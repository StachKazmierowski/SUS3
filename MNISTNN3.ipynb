{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np # to handle matrix and data operation\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "trainset = datasets.MNIST('./data/train', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('./data/test', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear2): Linear(in_features=576, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=2)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.linear2 = nn.Linear(6 * 6 * 16, 10)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.pool1(F.relu(self.conv1(X)))\n",
    "        X = self.pool2(F.relu(self.conv2(X)))\n",
    "        X = X.view(-1, 6 * 6 * 16)\n",
    "        X = self.linear2(X)\n",
    "        return X\n",
    "\n",
    "model = Net(device='cuda:0')\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "logps = model(images.to(device)) #log probabilities\n",
    "loss = criterion(logps, labels.to(device)) #calculate t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def accuracy(testloader, epoch):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs= model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(\"Accuracy\", 100 * correct / total)\n",
    "        return 100 * correct / total\n",
    "\n",
    "# accuracy(valloader, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.3448950183232625\n",
      "Epoch 0 - Validation loss: 0.12025214077089541\n",
      "on train set:\n",
      "Accuracy 96.015\n",
      "on test set:\n",
      "Accuracy 96.4\n",
      "Epoch 1 - Training loss: 0.10470779202381769\n",
      "Epoch 1 - Validation loss: 0.07472692991788395\n",
      "on train set:\n",
      "Accuracy 97.57833333333333\n",
      "on test set:\n",
      "Accuracy 97.74\n",
      "\n",
      "Training Time (in minutes) = 0.9309555411338806\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 2\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    running_val_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    for images, labels in valloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        running_val_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
    "        print(\"Epoch {} - Validation loss: {}\".format(e, running_val_loss/len(valloader)))\n",
    "        print(\"on train set:\")\n",
    "        accuracy(trainloader, e)\n",
    "        print(\"on test set:\")\n",
    "        accuracy(valloader, e)\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "PATH = './mnist_net'\n",
    "torch.save(model.state_dict(), PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Poniżej dane wskazujące na przetrenowania\n",
    "\n",
    "\n",
    "Epoch 0 - Training loss: 0.3483577066699664\n",
    "Epoch 0 - Training loss: 0.10861856871233962\n",
    "on train set:\n",
    "Accuracy 96.57\n",
    "on test set:\n",
    "Accuracy 96.76\n",
    "Epoch 1 - Training loss: 0.10320847239891688\n",
    "Epoch 1 - Training loss: 0.07951102484338962\n",
    "on train set:\n",
    "Accuracy 97.55\n",
    "on test set:\n",
    "Accuracy 97.52\n",
    "Epoch 2 - Training loss: 0.07951653525431951\n",
    "Epoch 2 - Training loss: 0.06962830385270591\n",
    "on train set:\n",
    "Accuracy 97.98\n",
    "on test set:\n",
    "Accuracy 97.79\n",
    "Epoch 3 - Training loss: 0.06738914438883463\n",
    "Epoch 3 - Training loss: 0.05580564471669852\n",
    "on train set:\n",
    "Accuracy 98.35833333333333\n",
    "on test set:\n",
    "Accuracy 98.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}